<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="C++23: flat_map, flat_set, et al." /><meta property="og:locale" content="en_US" /><meta name="description" content="C++23 is introducing some more data structures, some more associative containers. We are going to get the flat versions of map/set/multimap/multiset: flat_map flat_set flat_multimap flat_multiset These new types will work as drop-in replacements for their non-flat types. The goal of these new types is to provide different time and space complexities compared to the original containers. The non-flat versions’ implementations are using balanced binary trees under the hood which more-or-less defines their main characteristics. C++11 introduced the unordered versions of these containers, and even though in most cases they should be preferred, they are often neglected. As the name suggests, unordered containers are not sorted. Now we are getting sorted containers that are more effective in a big chunk of our use cases. As mentioned, the original containers use binary search trees, the unordered versions use hashmaps. The flat ones use sequence containers. In fact, the flat versions are not even containers, they are container adapters. Container adapters are interfaces created by limiting functionality in a pre-existing container and providing a different set of functionality. When you declare a container adapter, you have the option of specifying which sequence container should be the underlying container. The underlying data structure is configurable through template parameters, but they must be sequence containers with random access iterators. Why do I speak about template parameters in plural? Because for a flat_map, you can use different containers for keys and values. From now on, I’ll simply write about flat_map, but the observations are also valid for the other flat container adapters unless I explicitly write so. Specialties of a flat_{map|set} So what are the specialities of these container adapters over the usual associate containers? What are those different time and space complexities that it has to provide? Let’s start with enumerating the disadvantages, just to avoid thinking that a flat_map is too good to be true. Insertion and deletion are going to be slower On insertion and deletion iterators will become unstable The exception safety is weaker because moves and copies do happen, we don’t just pass around pointers anymore And we cannot store non-copyable, non-movable types in flat structures And now let’s see what we get for this price. We’ll get: Faster iteration Random access iterators instead of bidirectional iterators Smaller memory consumption Improved cache-friendliness due to contiguous memory layout Actually, all this comes from the fact that under a map you’ll find a balanced search tree, while under a flat_map, you’ll find a sequence container, like a std::vector. Let’s have a closer look at some of these items above. What happens when we insert into a map or when we delete from it and the tree has to be rebalanced? There will be no copies or moves, because each node in the map has a handle, a pointer to the data and only these handles will be moved around not the pointed objects. Once we understand this, we also take it evident that the flat versions have a better memory footprint. When you work on a contiguous memory area when you deal with a sequence container, you have no handles, no metadata to store. You simply have to deal with the data. You also have to work more on them when you insert/delete as it’s not enough to move around the handles anymore. If you want to go deeper into the cache friendliness topic, I’d recommend watching the talk of Bjorn Fahller at C++OnSea. He explained that even in use cases when we might think that a linked list would serve us better than a sequence container, the latter might be a better choice. Even if it has to perform more work. More work is sometimes faster as the bottleneck is not the CPU anymore, but the cache. With sequence containers, the CPU has to access contiguous parts of memory, which is particularly cache-friendly. One more word on speed As it was already mentioned, flat_map is an ordered map. If you give some inputs to it either at construction time or later, it will take care of keeping itself sorted. That requires some resources. But what if your data is already sorted? After all, C++ has the concept of not paying for what you don’t use. flat_map provides a solution for that! The standard library provides a tag type called sorted_unique_t and the flat_map constructors have overloads taking that tag as a first parameter. Not only the constructors but also those overloads of the insert method that take multiple elements to insert. If you construct a flat_map from elements that are already sorted, or when you insert a range of items that are already sorted, don’t forget to use the overloads with sorted_unique_t, because you can benefit from a significant performance gain. But beware! If you use a sorted_unique_t overload with unsorted data, the behaviour is undefined! All bets are off! How it differs in its API flat_map stores separately the keys and values, and the storage for those can be of different types. Because of that, there is a bunch of new constructors available. In addition, there are several new overloads for the constructor and the insert method taking the previously explained sorted_unique_t tag so that we don’t resort to already sorted items. The extract member method moves out both underlying storage containers. The extract function is overloaded with &amp;&amp; showing that the original object should not be used anymore. The other direction of moving data is also possible through the replace function. It takes containers as rvalue references and replaces the underlying containers with what was passed in. What if you want to use the new adaptors? You’ll still have to wait for the standard versions. At the moment of writing this article, no compiler supports the flat container adapters. At the same time, the proposal didn’t just come out of the blue. boost has had this feature for quite a while, which served as a basis for the standardization. You can go and experiment with it, if not on your local, you go to Compiler Explorer or Coliru. Conclusion In C++23, we are going to get some exciting new container adaptors in the standard library! The flat_{map|multimap|set|multiset} containers offer different space and time complexities compared to their normal, original versions. It favors fast iteration, lookup and lower memory consumption at the expense of potentially slower writes. At the same time, it still offers the benefits of having sorted containers, unlike the unordered_* versions. Although there is no compiler support for the time being, we can already learn about both from the standard or by using the boost versions! Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!" /><meta property="og:description" content="C++23 is introducing some more data structures, some more associative containers. We are going to get the flat versions of map/set/multimap/multiset: flat_map flat_set flat_multimap flat_multiset These new types will work as drop-in replacements for their non-flat types. The goal of these new types is to provide different time and space complexities compared to the original containers. The non-flat versions’ implementations are using balanced binary trees under the hood which more-or-less defines their main characteristics. C++11 introduced the unordered versions of these containers, and even though in most cases they should be preferred, they are often neglected. As the name suggests, unordered containers are not sorted. Now we are getting sorted containers that are more effective in a big chunk of our use cases. As mentioned, the original containers use binary search trees, the unordered versions use hashmaps. The flat ones use sequence containers. In fact, the flat versions are not even containers, they are container adapters. Container adapters are interfaces created by limiting functionality in a pre-existing container and providing a different set of functionality. When you declare a container adapter, you have the option of specifying which sequence container should be the underlying container. The underlying data structure is configurable through template parameters, but they must be sequence containers with random access iterators. Why do I speak about template parameters in plural? Because for a flat_map, you can use different containers for keys and values. From now on, I’ll simply write about flat_map, but the observations are also valid for the other flat container adapters unless I explicitly write so. Specialties of a flat_{map|set} So what are the specialities of these container adapters over the usual associate containers? What are those different time and space complexities that it has to provide? Let’s start with enumerating the disadvantages, just to avoid thinking that a flat_map is too good to be true. Insertion and deletion are going to be slower On insertion and deletion iterators will become unstable The exception safety is weaker because moves and copies do happen, we don’t just pass around pointers anymore And we cannot store non-copyable, non-movable types in flat structures And now let’s see what we get for this price. We’ll get: Faster iteration Random access iterators instead of bidirectional iterators Smaller memory consumption Improved cache-friendliness due to contiguous memory layout Actually, all this comes from the fact that under a map you’ll find a balanced search tree, while under a flat_map, you’ll find a sequence container, like a std::vector. Let’s have a closer look at some of these items above. What happens when we insert into a map or when we delete from it and the tree has to be rebalanced? There will be no copies or moves, because each node in the map has a handle, a pointer to the data and only these handles will be moved around not the pointed objects. Once we understand this, we also take it evident that the flat versions have a better memory footprint. When you work on a contiguous memory area when you deal with a sequence container, you have no handles, no metadata to store. You simply have to deal with the data. You also have to work more on them when you insert/delete as it’s not enough to move around the handles anymore. If you want to go deeper into the cache friendliness topic, I’d recommend watching the talk of Bjorn Fahller at C++OnSea. He explained that even in use cases when we might think that a linked list would serve us better than a sequence container, the latter might be a better choice. Even if it has to perform more work. More work is sometimes faster as the bottleneck is not the CPU anymore, but the cache. With sequence containers, the CPU has to access contiguous parts of memory, which is particularly cache-friendly. One more word on speed As it was already mentioned, flat_map is an ordered map. If you give some inputs to it either at construction time or later, it will take care of keeping itself sorted. That requires some resources. But what if your data is already sorted? After all, C++ has the concept of not paying for what you don’t use. flat_map provides a solution for that! The standard library provides a tag type called sorted_unique_t and the flat_map constructors have overloads taking that tag as a first parameter. Not only the constructors but also those overloads of the insert method that take multiple elements to insert. If you construct a flat_map from elements that are already sorted, or when you insert a range of items that are already sorted, don’t forget to use the overloads with sorted_unique_t, because you can benefit from a significant performance gain. But beware! If you use a sorted_unique_t overload with unsorted data, the behaviour is undefined! All bets are off! How it differs in its API flat_map stores separately the keys and values, and the storage for those can be of different types. Because of that, there is a bunch of new constructors available. In addition, there are several new overloads for the constructor and the insert method taking the previously explained sorted_unique_t tag so that we don’t resort to already sorted items. The extract member method moves out both underlying storage containers. The extract function is overloaded with &amp;&amp; showing that the original object should not be used anymore. The other direction of moving data is also possible through the replace function. It takes containers as rvalue references and replaces the underlying containers with what was passed in. What if you want to use the new adaptors? You’ll still have to wait for the standard versions. At the moment of writing this article, no compiler supports the flat container adapters. At the same time, the proposal didn’t just come out of the blue. boost has had this feature for quite a while, which served as a basis for the standardization. You can go and experiment with it, if not on your local, you go to Compiler Explorer or Coliru. Conclusion In C++23, we are going to get some exciting new container adaptors in the standard library! The flat_{map|multimap|set|multiset} containers offer different space and time complexities compared to their normal, original versions. It favors fast iteration, lookup and lower memory consumption at the expense of potentially slower writes. At the same time, it still offers the benefits of having sorted containers, unlike the unordered_* versions. Although there is no compiler support for the time being, we can already learn about both from the standard or by using the boost versions! Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!" /><link rel="canonical" href="https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" /><meta property="og:url" content="https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" /><meta property="og:site_name" content="Sandor Dargo’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2022-10-05T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="C++23: flat_map, flat_set, et al." /><meta name="twitter:site" content="@SandorDargo" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-09-16T14:41:06+02:00","datePublished":"2022-10-05T00:00:00+02:00","description":"C++23 is introducing some more data structures, some more associative containers. We are going to get the flat versions of map/set/multimap/multiset: flat_map flat_set flat_multimap flat_multiset These new types will work as drop-in replacements for their non-flat types. The goal of these new types is to provide different time and space complexities compared to the original containers. The non-flat versions’ implementations are using balanced binary trees under the hood which more-or-less defines their main characteristics. C++11 introduced the unordered versions of these containers, and even though in most cases they should be preferred, they are often neglected. As the name suggests, unordered containers are not sorted. Now we are getting sorted containers that are more effective in a big chunk of our use cases. As mentioned, the original containers use binary search trees, the unordered versions use hashmaps. The flat ones use sequence containers. In fact, the flat versions are not even containers, they are container adapters. Container adapters are interfaces created by limiting functionality in a pre-existing container and providing a different set of functionality. When you declare a container adapter, you have the option of specifying which sequence container should be the underlying container. The underlying data structure is configurable through template parameters, but they must be sequence containers with random access iterators. Why do I speak about template parameters in plural? Because for a flat_map, you can use different containers for keys and values. From now on, I’ll simply write about flat_map, but the observations are also valid for the other flat container adapters unless I explicitly write so. Specialties of a flat_{map|set} So what are the specialities of these container adapters over the usual associate containers? What are those different time and space complexities that it has to provide? Let’s start with enumerating the disadvantages, just to avoid thinking that a flat_map is too good to be true. Insertion and deletion are going to be slower On insertion and deletion iterators will become unstable The exception safety is weaker because moves and copies do happen, we don’t just pass around pointers anymore And we cannot store non-copyable, non-movable types in flat structures And now let’s see what we get for this price. We’ll get: Faster iteration Random access iterators instead of bidirectional iterators Smaller memory consumption Improved cache-friendliness due to contiguous memory layout Actually, all this comes from the fact that under a map you’ll find a balanced search tree, while under a flat_map, you’ll find a sequence container, like a std::vector. Let’s have a closer look at some of these items above. What happens when we insert into a map or when we delete from it and the tree has to be rebalanced? There will be no copies or moves, because each node in the map has a handle, a pointer to the data and only these handles will be moved around not the pointed objects. Once we understand this, we also take it evident that the flat versions have a better memory footprint. When you work on a contiguous memory area when you deal with a sequence container, you have no handles, no metadata to store. You simply have to deal with the data. You also have to work more on them when you insert/delete as it’s not enough to move around the handles anymore. If you want to go deeper into the cache friendliness topic, I’d recommend watching the talk of Bjorn Fahller at C++OnSea. He explained that even in use cases when we might think that a linked list would serve us better than a sequence container, the latter might be a better choice. Even if it has to perform more work. More work is sometimes faster as the bottleneck is not the CPU anymore, but the cache. With sequence containers, the CPU has to access contiguous parts of memory, which is particularly cache-friendly. One more word on speed As it was already mentioned, flat_map is an ordered map. If you give some inputs to it either at construction time or later, it will take care of keeping itself sorted. That requires some resources. But what if your data is already sorted? After all, C++ has the concept of not paying for what you don’t use. flat_map provides a solution for that! The standard library provides a tag type called sorted_unique_t and the flat_map constructors have overloads taking that tag as a first parameter. Not only the constructors but also those overloads of the insert method that take multiple elements to insert. If you construct a flat_map from elements that are already sorted, or when you insert a range of items that are already sorted, don’t forget to use the overloads with sorted_unique_t, because you can benefit from a significant performance gain. But beware! If you use a sorted_unique_t overload with unsorted data, the behaviour is undefined! All bets are off! How it differs in its API flat_map stores separately the keys and values, and the storage for those can be of different types. Because of that, there is a bunch of new constructors available. In addition, there are several new overloads for the constructor and the insert method taking the previously explained sorted_unique_t tag so that we don’t resort to already sorted items. The extract member method moves out both underlying storage containers. The extract function is overloaded with &amp;&amp; showing that the original object should not be used anymore. The other direction of moving data is also possible through the replace function. It takes containers as rvalue references and replaces the underlying containers with what was passed in. What if you want to use the new adaptors? You’ll still have to wait for the standard versions. At the moment of writing this article, no compiler supports the flat container adapters. At the same time, the proposal didn’t just come out of the blue. boost has had this feature for quite a while, which served as a basis for the standardization. You can go and experiment with it, if not on your local, you go to Compiler Explorer or Coliru. Conclusion In C++23, we are going to get some exciting new container adaptors in the standard library! The flat_{map|multimap|set|multiset} containers offer different space and time complexities compared to their normal, original versions. It favors fast iteration, lookup and lower memory consumption at the expense of potentially slower writes. At the same time, it still offers the benefits of having sorted containers, unlike the unordered_* versions. Although there is no compiler support for the time being, we can already learn about both from the standard or by using the boost versions! Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!","headline":"C++23: flat_map, flat_set, et al.","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map"},"url":"https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map"}</script><title>C++23: flat_map, flat_set, et al. | Sandor Dargo's Blog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-89625019-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-89625019-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/SANDOR_DARGO_ROUND.JPG" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Sandor Dargo's Blog</a></div><div class="site-subtitle font-italic">On C++, software development and books</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/books/" class="nav-link"> <i class="fa-fw fas fa-book ml-xl-3 mr-xl-3 unloaded"></i> <span>BOOKS</span> </a><li class="nav-item"> <a href="/speaking/" class="nav-link"> <i class="fa-fw fas fa-microphone ml-xl-3 mr-xl-3 unloaded"></i> <span>SPEAKING</span> </a><li class="nav-item"> <a href="/dailycpp/" class="nav-link"> <i class="fa-fw fas fa-link ml-xl-3 mr-xl-3 unloaded"></i> <span>DAILY C++</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>HI...</span> </a></ul><ul class="w-100"><li class="nav-item"> <a href="https://www.patreon.com/sandordargo" class="nav-link"> <img src="https://c5.patreon.com/external/logo/become_a_patron_button.png"></a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/sandordargo" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/SandorDargo" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['sandor.dargo','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/blog"> Blog </a> </span> <span> <a href="/2022"> 2022 </a> </span> <span> <a href="/10"> 10 </a> </span> <span> <a href="/05"> 05 </a> </span> <span>C++23: flat_map, flat_set, et al.</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>C++23: flat_map, flat_set, et al.</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Sandor Dargo </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Oct 5, 2022, 12:00 AM +0200" prep="on" > Oct 5, 2022 <i class="unloaded">2022-10-05T00:00:00+02:00</i> </span></div><div> <span> <span class="timeago lastmod" data-toggle="tooltip" data-placement="bottom" title="Sat, Sep 16, 2023, 2:41 PM +0200" prefix="Updated " > Sep 16, 2023 <i class="unloaded">2023-09-16T14:41:06+02:00</i> </span> </span> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1120 words">6 min</span></div></div><div class="post-content"><p><a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p0429r9.pdf">C++23 is introducing some more data structures</a>, some more associative containers. We are going to get the <em>flat</em> versions of <code class="language-plaintext highlighter-rouge">map</code>/<code class="language-plaintext highlighter-rouge">set</code>/<code class="language-plaintext highlighter-rouge">multimap</code>/<code class="language-plaintext highlighter-rouge">multiset</code>:</p><ul><li><code class="language-plaintext highlighter-rouge">flat_map</code><li><code class="language-plaintext highlighter-rouge">flat_set</code><li><code class="language-plaintext highlighter-rouge">flat_multimap</code><li><code class="language-plaintext highlighter-rouge">flat_multiset</code></ul><p>These new types will work as drop-in replacements for their non-flat types. The goal of these new types is to provide different time and space complexities compared to the original containers. The non-flat versions’ implementations are using balanced binary trees under the hood which more-or-less defines their main characteristics. C++11 introduced the unordered versions of these containers, and even though in most cases they should be preferred, they are often neglected. As the name suggests, unordered containers are not sorted.</p><p>Now we are getting sorted containers that are more effective in a big chunk of our use cases.</p><p>As mentioned, the original containers use binary search trees, the unordered versions use hashmaps. The flat ones use sequence containers. In fact, the flat versions are not even containers, they are container adapters.</p><blockquote><p><em><a href="https://stackoverflow.com/questions/3873802/what-are-containers-adapters-c">Container adapters</a></em> are interfaces created by limiting functionality in a pre-existing container and providing a different set of functionality. When you declare a container adapter, you have the option of specifying which sequence container should be the underlying container.</p></blockquote><p>The underlying data structure is configurable through template parameters, but they must be sequence containers with random access iterators. Why do I speak about template parameters in plural? Because for a <code class="language-plaintext highlighter-rouge">flat_map</code>, you can use different containers for keys and values. From now on, I’ll simply write about <code class="language-plaintext highlighter-rouge">flat_map</code>, but the observations are also valid for the other <em>flat</em> container adapters unless I explicitly write so.</p><h2 id="specialties-of-a-flat_mapset">Specialties of a <code class="language-plaintext highlighter-rouge">flat_{map|set}</code></h2><p>So what are the specialities of these container adapters over the usual associate containers? What are those different time and space complexities that it has to provide? Let’s start with enumerating the disadvantages, just to avoid thinking that a <code class="language-plaintext highlighter-rouge">flat_map</code> is too good to be true.</p><ul><li>Insertion and deletion are going to be slower<li>On insertion and deletion iterators will become unstable<li>The exception safety is weaker because moves and copies do happen, we don’t just pass around pointers anymore<li>And we cannot store non-copyable, non-movable types in <em>flat</em> structures</ul><p>And now let’s see what we get for this price. We’ll get:</p><ul><li>Faster iteration<li>Random access iterators instead of bidirectional iterators<li>Smaller memory consumption<li>Improved cache-friendliness due to contiguous memory layout</ul><p>Actually, all this comes from the fact that under a <code class="language-plaintext highlighter-rouge">map</code> you’ll find a balanced search tree, while under a <code class="language-plaintext highlighter-rouge">flat_map</code>, you’ll find a sequence container, like a <code class="language-plaintext highlighter-rouge">std::vector</code>.</p><p>Let’s have a closer look at some of these items above.</p><p>What happens when we insert into a <code class="language-plaintext highlighter-rouge">map</code> or when we delete from it and the tree has to be rebalanced? There will be no copies or moves, because each node in the <code class="language-plaintext highlighter-rouge">map</code> has a handle, a pointer to the data and only these handles will be moved around not the pointed objects.</p><p>Once we understand this, we also take it evident that the flat versions have a better memory footprint. When you work on a contiguous memory area when you deal with a sequence container, you have no handles, no metadata to store. You simply have to deal with the data. You also have to work more on them when you insert/delete as it’s not enough to move around the handles anymore.</p><p>If you want to go deeper into the cache friendliness topic, I’d recommend watching the talk of <a href="https://www.youtube.com/watch?v=yyNWKHoDtMs">Bjorn Fahller at C++OnSea</a>. He explained that even in use cases when we might think that a linked list would serve us better than a sequence container, the latter might be a better choice. Even if it has to perform more work. More work is sometimes faster as the bottleneck is not the CPU anymore, but the cache. With sequence containers, the CPU has to access contiguous parts of memory, which is particularly cache-friendly.</p><h2 id="one-more-word-on-speed">One more word on speed</h2><p>As it was already mentioned, <code class="language-plaintext highlighter-rouge">flat_map</code> is an ordered map. If you give some inputs to it either at construction time or later, it will take care of keeping itself sorted. That requires some resources. But what if your data is already sorted? After all, C++ has the concept of not paying for what you don’t use.</p><p><code class="language-plaintext highlighter-rouge">flat_map</code> provides a solution for that!</p><p>The standard library provides a tag type called <code class="language-plaintext highlighter-rouge">sorted_unique_t</code> and the <code class="language-plaintext highlighter-rouge">flat_map</code> constructors have overloads taking that tag as a first parameter. Not only the constructors but also those overloads of the <code class="language-plaintext highlighter-rouge">insert</code> method that take multiple elements to insert. If you construct a <code class="language-plaintext highlighter-rouge">flat_map</code> from elements that are already sorted, or when you <code class="language-plaintext highlighter-rouge">insert</code> a range of items that are already sorted, don’t forget to use the overloads with <code class="language-plaintext highlighter-rouge">sorted_unique_t</code>, because you can benefit from a significant performance gain.</p><p>But beware! If you use a <code class="language-plaintext highlighter-rouge">sorted_unique_t</code> overload with unsorted data, the behaviour is undefined! All bets are off!</p><h2 id="how-it-differs-in-its-api">How it differs in its API</h2><p><code class="language-plaintext highlighter-rouge">flat_map</code> stores separately the keys and values, and the storage for those can be of different types. Because of that, there is a bunch of new constructors available. In addition, there are several new overloads for the constructor and the <code class="language-plaintext highlighter-rouge">insert</code> method taking the previously explained <code class="language-plaintext highlighter-rouge">sorted_unique_t</code> tag so that we don’t resort to already sorted items.</p><p>The <code class="language-plaintext highlighter-rouge">extract</code> member method moves out both underlying storage containers. The <code class="language-plaintext highlighter-rouge">extract</code> function is overloaded with <code class="language-plaintext highlighter-rouge">&amp;&amp;</code> showing that the original object should not be used anymore.</p><p>The other direction of moving data is also possible through the <code class="language-plaintext highlighter-rouge">replace</code> function. It takes containers as <em>rvalue</em> references and replaces the underlying containers with what was passed in.</p><h2 id="what-if-you-want-to-use-the-new-adaptors">What if you want to use the new adaptors?</h2><p>You’ll still have to wait for the standard versions. At the moment of writing this article, <a href="https://en.cppreference.com/w/cpp/compiler_support/23">no compiler supports the flat container adapters</a>.</p><p>At the same time, the proposal didn’t just come out of the blue. <a href="https://www.boost.org/doc/libs/1_80_0/doc/html/boost_container_header_reference.html#header.boost.container.flat_map_hpp"><code class="language-plaintext highlighter-rouge">boost</code> has had this feature for quite a while</a>, which served as a basis for the standardization. You can go and experiment with it, if not on your local, you go to <a href="https://godbolt.org/z/x3vY1f6rz">Compiler Explorer</a> or <a href="http://coliru.stacked-crooked.com/a/84be54a775297036">Coliru</a>.</p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="/assets/img/flat_map.png" alt="Flat map in use" /></p><h2 id="conclusion">Conclusion</h2><p>In C++23, we are going to get some exciting new container adaptors in the standard library! The <code class="language-plaintext highlighter-rouge">flat_{map|multimap|set|multiset}</code> containers offer different space and time complexities compared to their normal, original versions. It favors fast iteration, lookup and lower memory consumption at the expense of potentially slower writes. At the same time, it still offers the benefits of having sorted containers, unlike the <code class="language-plaintext highlighter-rouge">unordered_*</code> versions.</p><p>Although there is no compiler support for the time being, we can already learn about <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2022/p0429r9.pdf">both from the standard</a> or by using <a href="https://www.boost.org/doc/libs/1_80_0/doc/html/boost_container_header_reference.html#header.boost.container.flat_map_hpp">the boost versions</a>!</p><h2 id="connect-deeper">Connect deeper</h2><p>If you liked this article, please</p><ul><li>hit on the like button,<li><a href="http://eepurl.com/gvcv1j">subscribe to my newsletter</a><li>and let’s connect on <a href="https://twitter.com/SandorDargo">Twitter</a>!</ul><a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/dev/'>dev</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/cpp/" class="post-tag no-text-decoration" >cpp</a> <a href="/tags/cpp23/" class="post-tag no-text-decoration" >cpp23</a> <a href="/tags/flat-map/" class="post-tag no-text-decoration" >flat_map</a> <a href="/tags/flat-set/" class="post-tag no-text-decoration" >flat_set</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a><div class="share-wrapper"> <a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=C++23: flat_map, flat_set, et al. - Sandor Dargo's Blog&url=https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=C++23: flat_map, flat_set, et al. - Sandor Dargo's Blog&u=https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=C++23: flat_map, flat_set, et al. - Sandor Dargo's Blog&url=https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://news.ycombinator.com/submitlink?t=C++23: flat_map, flat_set, et al. - Sandor Dargo's Blog&u=https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map" data-toggle="tooltip" data-placement="top" title="HackerNews" target="_blank" rel="noopener" aria-label="HackerNews"> <i class="fa-fw fab fa-hacker-news"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/blog/2026/01/21/clocks-part-8-cpp20-timezones">Time in C++: C++20 Brought Us Time Zones</a><li><a href="/blog/2019/04/10/lesson-of-a-booking-dont-trust-the-system">Lesson of a booking: Don't trust the system!</a><li><a href="/blog/2020/07/22/always-catch-exceptions-by-reference">Why should we always catch exceptions by reference?</a><li><a href="/blog/2020/11/28/emergent-design">Emergent Design: The Evolutionary Nature of Professional Software Development by Scott Bain</a><li><a href="/blog/2021/10/06/airy-code-reviews">Bring some fresh AIR and write effective code review comments</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/cpp/">cpp</a> <a class="post-tag" href="/tags/books/">books</a> <a class="post-tag" href="/tags/watercooler/">watercooler</a> <a class="post-tag" href="/tags/career/">career</a> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/cpp23/">cpp23</a> <a class="post-tag" href="/tags/stl/">stl</a> <a class="post-tag" href="/tags/algorithms/">algorithms</a> <a class="post-tag" href="/tags/self-improvement/">self-improvement</a> <a class="post-tag" href="/tags/management/">management</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/blog/2022/11/23/cpp23-changes-to-lambdas"><div class="card-body"> <span class="timeago small" > Nov 23, 2022 <i class="unloaded">2022-11-23T00:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>C++23: How lambdas are going to change?</h3><div class="text-muted small"><p> C++23 is coming soon and it will change how lambdas work in 3 different ways. They will not only become simpler in certain circumstances but they will be also aligned more with other features of th...</p></div></div></a></div><div class="card"> <a href="/blog/2022/11/30/cpp23-auto-and-decay-copy"><div class="card-body"> <span class="timeago small" > Nov 30, 2022 <i class="unloaded">2022-11-30T00:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>C++23: auto(x) and decay copy</h3><div class="text-muted small"><p> When I first saw auto I thought that woah, not so fast, how am I going to know the type of my variables? Then I started to understand that auto helps in so many different ways. It helps remove the ...</p></div></div></a></div><div class="card"> <a href="/blog/2022/12/07/inout_ptr-and-out_ptr"><div class="card-body"> <span class="timeago small" > Dec 7, 2022 <i class="unloaded">2022-12-07T00:00:00+01:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>C++23: std::out_ptr and std::inout_ptr</h3><div class="text-muted small"><p> This week, let’s continue exploring the new world of C++23. We are going to discuss two new standard library functions and their outputs (std::out_ptr, std::inout_ptr), two new standard library typ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/blog/2022/09/28/5-tips-to-find-your-next-job" class="btn btn-outline-primary" prompt="Older"><p>5 tips to find your next job</p></a> <a href="/blog/2022/10/08/battle-hardened-developer" class="btn btn-outline-primary" prompt="Newer"><p>The Battle Hardened Developer by Fiodar Sazanavets</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//sandordargo-github-io.disqus.com/embed.js', disqusConfig: function() { this.page.title = 'C++23: flat_map, flat_set, et al.'; this.page.url = 'https://www.sandordargo.com/blog/2022/10/05/cpp23-flat_map'; this.page.identifier = '/blog/2022/10/05/cpp23-flat_map'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><div id="amzn-assoc-ad-be5a767b-3346-40aa-bc00-2eff0ce33d2b"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=be5a767b-3346-40aa-bc00-2eff0ce33d2b"></script> <script type="text/javascript" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script> <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us16.list-manage.com","uuid":"b073dbd5c29322302f59a8cd8","lid":"d26240427e"}) })</script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2026 <a href="https://twitter.com/SandorDargo">Sandor Dargo</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/cpp/">cpp</a> <a class="post-tag" href="/tags/books/">books</a> <a class="post-tag" href="/tags/watercooler/">watercooler</a> <a class="post-tag" href="/tags/career/">career</a> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/cpp23/">cpp23</a> <a class="post-tag" href="/tags/stl/">stl</a> <a class="post-tag" href="/tags/algorithms/">algorithms</a> <a class="post-tag" href="/tags/self-improvement/">self improvement</a> <a class="post-tag" href="/tags/management/">management</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://www.sandordargo.com{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
