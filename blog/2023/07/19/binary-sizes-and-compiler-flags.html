<!DOCTYPE html><html lang="en-US" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"><meta name="pv-cache-enabled" content="false"><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Binary sizes and compiler flags" /><meta property="og:locale" content="en_US" /><meta name="description" content="During the last few months, we discussed a lot about how to write code to limit the size of our binary. We should think twice if we want to turn a class into polymorphic, exceptions also take a heavy toll and we might end up defaulting special functions in the cpp file which is quite unintuitive. There are practices going against common sense and also that can be considered a best practice in any case. I think it’s good to know about them. But how you compile your code is also important! Something I briefly mentioned in one of the first parts when it comes to optimization levels. But at that time we only talked about -Os and -Oz. Interestingly, they didn’t work well in my local experiments. -O3 almost always produced better results and never worse. Maybe my scenarios were not big enough. A few weeks ago, I presented my findings at MUC++, and I was focusing on the programming techniques. During the after-talk discussion, I was told that if binary size is really a concern for me, then I should definitely try certain not-so-well-known compiler and linker settings and they kindly gave me a few suggestions. Many of them had been already applied by others, but now at least I understand what they mean! Let me share those with you too, so that you also know and can experiment with them. Optimize for space: -Os I already mentioned -Os at the beginning of the series, but I think it’s important to bring it up once again. One usually builds with -O0 for debug builds to have the most information available for an eventual debugging session. On the other hand, for release builds, one most often uses -O3 to have an executable that is fast as possible - thanks to compiler optimizations. But if your goal is to have the smallest binary possible, you should consider -Os (or -Oz depending on the compiler). The compiler will optimize for space. It doesn’t give up performance though. It’ll do most of the optimizations that are done on -O2 except for a few that would enlarge your binary, such as loop unrolling (we’ll see that later). Link Time Optimization What does the name Link Time Optimization (LTO in short) tell us? Not much to be honest. Some optimization would happen during link time, right?! Fair enough. It has another name which is a bit more revealing: Inter Procedural Optimization! So when LTO/IPO is enabled, the linker looks beyond individual object files and performs optimizations such as removing functions and even related global code and data that are never used. Here you can find a nice example. When LTO is enabled, source files are not directly translated to ELF/Mach-O or other object files, but they are translated into an intermediary bitcode. Out of those files, the linker can extract all the dependency information that it needs to finally optimize away some of the code and then it can create the optimized ELF/Mach-O/etc files that are optimized by the linker. The fundamental way to trigger it is to pass -flto, but it has further options which are worth looking into when you decide to use it. These go beyond the scope of this article, but we might look into it in a future post. -fdata-sections / -ffunction-sections and -Wl,--gc-sections First of all, let me explain why I mention 3 options right away in one section. -fdata-sections and -ffunction-sections are similar in their nature and they won’t help you unless you pass -Wl,--gc-sections as well. -fdata-sections and -ffunction-sections place each piece of global data item and function respectively into its own section in the object file. If you only use these, your final binary will be larger. But if you pass -Wl,--gc-sections, the unused sections will not be part of your compiled and linked file and you can end up with a smaller binary. Now let’s have a couple of remarks. -Wl,--gc-sections seems odd as a parameter when you first see it. Passing -Wl to gcc or clang means that what you’re passing after is meant to be an option for the linker, and not for the compiler. If you invoke the linker separately, you will have to pass --gc-sections on its own. My second remark is about unused sections. If you read about these options, people often mention “unused code”. That’s misleading. You might think that this is a tool then to identify code that is written but nowhere used. That’s not the case. When the linker has to resolve a certain symbol - let’s say foo() - in another object file, then once it finds it, it’ll include the entire .text section. Potentially with lots of code that you don’t use. Unused code in that sense. If each function and piece of global data have its own section, the linker will only include the needed sections thus you might gain a considerable amount of space. And here is the third remark. Don’t forget to measure. Depending on your code, you might not gain a lot of space and if that’s your case, then don’t use these because they make compilations and linking slower and if there are some “magic” sections that are needed for your program but they are nowhere referenced in the functions that you use, your program will misbehave. You can find more info on this here starting from slide 9. All-in-all, these options are really useful, just don’t forget to measure and test first! -Wl,--icf=all or -Wl,--icf==safe We often have functions whose bodies are almost identical. You might say that’s not good and one should follow the DRY principle and don’t repeat the same code over and over again, but it’s not always the case, you might not want to reuse the same code in completely different contexts. In any case, you might end up with identical code. Of course, when you want to bring down binary size, it feels like a big waste to store the generated code for identical functions. Luckily, compiler and linker implementers already thought about that! What you might look for is _identical code folding__, in short icf. According to some Google experiments, this technique might reduce the size of your binary by 6%! You can turn it on by passing --icf=all to your linker, or -Wl,--icf=all if you go through your compiler. We must note that ICF might cause some issues if you use functions as keys in a map for example. Then the same piece of code - which would normally be two different pieces of code - would practically be used as a map key twice which is obviously a problem. To avoid such issues, you can use --icf=safe. It will decrease a bit the gain, but the benefits will be still significant. When you want to benefit from ICF, you should also consider setting -faddrsig. This switch controls whether Clang (have you found something similar in GCC?) emits an address-significance table into object files. These tables allow the linkers to implement ICF without too many false positives. -mllvm -inline-threshold=&lt;n&gt; Clang lets you drive - or at least give a hint - how much it should inline functions through the -mllvm -inline-threshold=&lt;n&gt; setting where n is set to 255 by default. The corresponding compiler setting for gcc is -finline-limit. The smaller n is, the less inlining will happen, thus the smaller your binary will be. On the other hand, by increasing the value of n, you will end up with more inlining, a bigger binary and potentially faster code. Don’t just play with this setting blindly, measure the effects to avoid bad surprises, both in terms of binary size and also regarding run-time performance. -fno-unroll-loops A well-known optimization technique used by all compilers is to replace loops with their body repeated the necessary number of times. 1 2 3 4 5 6 7 8 9 10 11 12 // the original loop for (size_t i = 0; i &lt; 5; ++i) { foo(); } // the unrolled version foo(); foo(); foo(); foo(); foo(); If someone would write the latter code, you’d never let it merge. Still, the compiler might do this optimization. It’s bad for the binary size, but it might be better for the run-time there is no need to jump around and maintain a loop variable. If you’re desperate to gain a few bytes, you might try this! Conclusion In this article, we reviewed compiler and linker options that help us reduce the size of the binary. Just don’t forget to measure the effects, because these are usually compromises between the space your executable needs and the time it requires to execute. Which ones you can take are always based on your constraints. Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!" /><meta property="og:description" content="During the last few months, we discussed a lot about how to write code to limit the size of our binary. We should think twice if we want to turn a class into polymorphic, exceptions also take a heavy toll and we might end up defaulting special functions in the cpp file which is quite unintuitive. There are practices going against common sense and also that can be considered a best practice in any case. I think it’s good to know about them. But how you compile your code is also important! Something I briefly mentioned in one of the first parts when it comes to optimization levels. But at that time we only talked about -Os and -Oz. Interestingly, they didn’t work well in my local experiments. -O3 almost always produced better results and never worse. Maybe my scenarios were not big enough. A few weeks ago, I presented my findings at MUC++, and I was focusing on the programming techniques. During the after-talk discussion, I was told that if binary size is really a concern for me, then I should definitely try certain not-so-well-known compiler and linker settings and they kindly gave me a few suggestions. Many of them had been already applied by others, but now at least I understand what they mean! Let me share those with you too, so that you also know and can experiment with them. Optimize for space: -Os I already mentioned -Os at the beginning of the series, but I think it’s important to bring it up once again. One usually builds with -O0 for debug builds to have the most information available for an eventual debugging session. On the other hand, for release builds, one most often uses -O3 to have an executable that is fast as possible - thanks to compiler optimizations. But if your goal is to have the smallest binary possible, you should consider -Os (or -Oz depending on the compiler). The compiler will optimize for space. It doesn’t give up performance though. It’ll do most of the optimizations that are done on -O2 except for a few that would enlarge your binary, such as loop unrolling (we’ll see that later). Link Time Optimization What does the name Link Time Optimization (LTO in short) tell us? Not much to be honest. Some optimization would happen during link time, right?! Fair enough. It has another name which is a bit more revealing: Inter Procedural Optimization! So when LTO/IPO is enabled, the linker looks beyond individual object files and performs optimizations such as removing functions and even related global code and data that are never used. Here you can find a nice example. When LTO is enabled, source files are not directly translated to ELF/Mach-O or other object files, but they are translated into an intermediary bitcode. Out of those files, the linker can extract all the dependency information that it needs to finally optimize away some of the code and then it can create the optimized ELF/Mach-O/etc files that are optimized by the linker. The fundamental way to trigger it is to pass -flto, but it has further options which are worth looking into when you decide to use it. These go beyond the scope of this article, but we might look into it in a future post. -fdata-sections / -ffunction-sections and -Wl,--gc-sections First of all, let me explain why I mention 3 options right away in one section. -fdata-sections and -ffunction-sections are similar in their nature and they won’t help you unless you pass -Wl,--gc-sections as well. -fdata-sections and -ffunction-sections place each piece of global data item and function respectively into its own section in the object file. If you only use these, your final binary will be larger. But if you pass -Wl,--gc-sections, the unused sections will not be part of your compiled and linked file and you can end up with a smaller binary. Now let’s have a couple of remarks. -Wl,--gc-sections seems odd as a parameter when you first see it. Passing -Wl to gcc or clang means that what you’re passing after is meant to be an option for the linker, and not for the compiler. If you invoke the linker separately, you will have to pass --gc-sections on its own. My second remark is about unused sections. If you read about these options, people often mention “unused code”. That’s misleading. You might think that this is a tool then to identify code that is written but nowhere used. That’s not the case. When the linker has to resolve a certain symbol - let’s say foo() - in another object file, then once it finds it, it’ll include the entire .text section. Potentially with lots of code that you don’t use. Unused code in that sense. If each function and piece of global data have its own section, the linker will only include the needed sections thus you might gain a considerable amount of space. And here is the third remark. Don’t forget to measure. Depending on your code, you might not gain a lot of space and if that’s your case, then don’t use these because they make compilations and linking slower and if there are some “magic” sections that are needed for your program but they are nowhere referenced in the functions that you use, your program will misbehave. You can find more info on this here starting from slide 9. All-in-all, these options are really useful, just don’t forget to measure and test first! -Wl,--icf=all or -Wl,--icf==safe We often have functions whose bodies are almost identical. You might say that’s not good and one should follow the DRY principle and don’t repeat the same code over and over again, but it’s not always the case, you might not want to reuse the same code in completely different contexts. In any case, you might end up with identical code. Of course, when you want to bring down binary size, it feels like a big waste to store the generated code for identical functions. Luckily, compiler and linker implementers already thought about that! What you might look for is _identical code folding__, in short icf. According to some Google experiments, this technique might reduce the size of your binary by 6%! You can turn it on by passing --icf=all to your linker, or -Wl,--icf=all if you go through your compiler. We must note that ICF might cause some issues if you use functions as keys in a map for example. Then the same piece of code - which would normally be two different pieces of code - would practically be used as a map key twice which is obviously a problem. To avoid such issues, you can use --icf=safe. It will decrease a bit the gain, but the benefits will be still significant. When you want to benefit from ICF, you should also consider setting -faddrsig. This switch controls whether Clang (have you found something similar in GCC?) emits an address-significance table into object files. These tables allow the linkers to implement ICF without too many false positives. -mllvm -inline-threshold=&lt;n&gt; Clang lets you drive - or at least give a hint - how much it should inline functions through the -mllvm -inline-threshold=&lt;n&gt; setting where n is set to 255 by default. The corresponding compiler setting for gcc is -finline-limit. The smaller n is, the less inlining will happen, thus the smaller your binary will be. On the other hand, by increasing the value of n, you will end up with more inlining, a bigger binary and potentially faster code. Don’t just play with this setting blindly, measure the effects to avoid bad surprises, both in terms of binary size and also regarding run-time performance. -fno-unroll-loops A well-known optimization technique used by all compilers is to replace loops with their body repeated the necessary number of times. 1 2 3 4 5 6 7 8 9 10 11 12 // the original loop for (size_t i = 0; i &lt; 5; ++i) { foo(); } // the unrolled version foo(); foo(); foo(); foo(); foo(); If someone would write the latter code, you’d never let it merge. Still, the compiler might do this optimization. It’s bad for the binary size, but it might be better for the run-time there is no need to jump around and maintain a loop variable. If you’re desperate to gain a few bytes, you might try this! Conclusion In this article, we reviewed compiler and linker options that help us reduce the size of the binary. Just don’t forget to measure the effects, because these are usually compromises between the space your executable needs and the time it requires to execute. Which ones you can take are always based on your constraints. Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!" /><link rel="canonical" href="https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" /><meta property="og:url" content="https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" /><meta property="og:site_name" content="Sandor Dargo’s Blog" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2023-07-19T00:00:00+02:00" /><meta name="twitter:card" content="summary" /><meta property="twitter:title" content="Binary sizes and compiler flags" /><meta name="twitter:site" content="@SandorDargo" /><meta name="google-site-verification" content="google_meta_tag_verification" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-07-19T00:00:00+02:00","datePublished":"2023-07-19T00:00:00+02:00","description":"During the last few months, we discussed a lot about how to write code to limit the size of our binary. We should think twice if we want to turn a class into polymorphic, exceptions also take a heavy toll and we might end up defaulting special functions in the cpp file which is quite unintuitive. There are practices going against common sense and also that can be considered a best practice in any case. I think it’s good to know about them. But how you compile your code is also important! Something I briefly mentioned in one of the first parts when it comes to optimization levels. But at that time we only talked about -Os and -Oz. Interestingly, they didn’t work well in my local experiments. -O3 almost always produced better results and never worse. Maybe my scenarios were not big enough. A few weeks ago, I presented my findings at MUC++, and I was focusing on the programming techniques. During the after-talk discussion, I was told that if binary size is really a concern for me, then I should definitely try certain not-so-well-known compiler and linker settings and they kindly gave me a few suggestions. Many of them had been already applied by others, but now at least I understand what they mean! Let me share those with you too, so that you also know and can experiment with them. Optimize for space: -Os I already mentioned -Os at the beginning of the series, but I think it’s important to bring it up once again. One usually builds with -O0 for debug builds to have the most information available for an eventual debugging session. On the other hand, for release builds, one most often uses -O3 to have an executable that is fast as possible - thanks to compiler optimizations. But if your goal is to have the smallest binary possible, you should consider -Os (or -Oz depending on the compiler). The compiler will optimize for space. It doesn’t give up performance though. It’ll do most of the optimizations that are done on -O2 except for a few that would enlarge your binary, such as loop unrolling (we’ll see that later). Link Time Optimization What does the name Link Time Optimization (LTO in short) tell us? Not much to be honest. Some optimization would happen during link time, right?! Fair enough. It has another name which is a bit more revealing: Inter Procedural Optimization! So when LTO/IPO is enabled, the linker looks beyond individual object files and performs optimizations such as removing functions and even related global code and data that are never used. Here you can find a nice example. When LTO is enabled, source files are not directly translated to ELF/Mach-O or other object files, but they are translated into an intermediary bitcode. Out of those files, the linker can extract all the dependency information that it needs to finally optimize away some of the code and then it can create the optimized ELF/Mach-O/etc files that are optimized by the linker. The fundamental way to trigger it is to pass -flto, but it has further options which are worth looking into when you decide to use it. These go beyond the scope of this article, but we might look into it in a future post. -fdata-sections / -ffunction-sections and -Wl,--gc-sections First of all, let me explain why I mention 3 options right away in one section. -fdata-sections and -ffunction-sections are similar in their nature and they won’t help you unless you pass -Wl,--gc-sections as well. -fdata-sections and -ffunction-sections place each piece of global data item and function respectively into its own section in the object file. If you only use these, your final binary will be larger. But if you pass -Wl,--gc-sections, the unused sections will not be part of your compiled and linked file and you can end up with a smaller binary. Now let’s have a couple of remarks. -Wl,--gc-sections seems odd as a parameter when you first see it. Passing -Wl to gcc or clang means that what you’re passing after is meant to be an option for the linker, and not for the compiler. If you invoke the linker separately, you will have to pass --gc-sections on its own. My second remark is about unused sections. If you read about these options, people often mention “unused code”. That’s misleading. You might think that this is a tool then to identify code that is written but nowhere used. That’s not the case. When the linker has to resolve a certain symbol - let’s say foo() - in another object file, then once it finds it, it’ll include the entire .text section. Potentially with lots of code that you don’t use. Unused code in that sense. If each function and piece of global data have its own section, the linker will only include the needed sections thus you might gain a considerable amount of space. And here is the third remark. Don’t forget to measure. Depending on your code, you might not gain a lot of space and if that’s your case, then don’t use these because they make compilations and linking slower and if there are some “magic” sections that are needed for your program but they are nowhere referenced in the functions that you use, your program will misbehave. You can find more info on this here starting from slide 9. All-in-all, these options are really useful, just don’t forget to measure and test first! -Wl,--icf=all or -Wl,--icf==safe We often have functions whose bodies are almost identical. You might say that’s not good and one should follow the DRY principle and don’t repeat the same code over and over again, but it’s not always the case, you might not want to reuse the same code in completely different contexts. In any case, you might end up with identical code. Of course, when you want to bring down binary size, it feels like a big waste to store the generated code for identical functions. Luckily, compiler and linker implementers already thought about that! What you might look for is _identical code folding__, in short icf. According to some Google experiments, this technique might reduce the size of your binary by 6%! You can turn it on by passing --icf=all to your linker, or -Wl,--icf=all if you go through your compiler. We must note that ICF might cause some issues if you use functions as keys in a map for example. Then the same piece of code - which would normally be two different pieces of code - would practically be used as a map key twice which is obviously a problem. To avoid such issues, you can use --icf=safe. It will decrease a bit the gain, but the benefits will be still significant. When you want to benefit from ICF, you should also consider setting -faddrsig. This switch controls whether Clang (have you found something similar in GCC?) emits an address-significance table into object files. These tables allow the linkers to implement ICF without too many false positives. -mllvm -inline-threshold=&lt;n&gt; Clang lets you drive - or at least give a hint - how much it should inline functions through the -mllvm -inline-threshold=&lt;n&gt; setting where n is set to 255 by default. The corresponding compiler setting for gcc is -finline-limit. The smaller n is, the less inlining will happen, thus the smaller your binary will be. On the other hand, by increasing the value of n, you will end up with more inlining, a bigger binary and potentially faster code. Don’t just play with this setting blindly, measure the effects to avoid bad surprises, both in terms of binary size and also regarding run-time performance. -fno-unroll-loops A well-known optimization technique used by all compilers is to replace loops with their body repeated the necessary number of times. 1 2 3 4 5 6 7 8 9 10 11 12 // the original loop for (size_t i = 0; i &lt; 5; ++i) { foo(); } // the unrolled version foo(); foo(); foo(); foo(); foo(); If someone would write the latter code, you’d never let it merge. Still, the compiler might do this optimization. It’s bad for the binary size, but it might be better for the run-time there is no need to jump around and maintain a loop variable. If you’re desperate to gain a few bytes, you might try this! Conclusion In this article, we reviewed compiler and linker options that help us reduce the size of the binary. Just don’t forget to measure the effects, because these are usually compromises between the space your executable needs and the time it requires to execute. Which ones you can take are always based on your constraints. Connect deeper If you liked this article, please hit on the like button, subscribe to my newsletter and let’s connect on Twitter!","headline":"Binary sizes and compiler flags","mainEntityOfPage":{"@type":"WebPage","@id":"https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags"},"url":"https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags"}</script><title>Binary sizes and compiler flags | Sandor Dargo's Blog</title><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="icon" href="/assets/img/favicons/favicon.ico" type="image/x-icon"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon.png"><link rel="apple-touch-icon" href="/assets/img/favicons/apple-icon-precomposed.png"><link rel="apple-touch-icon" sizes="57x57" href="/assets/img/favicons/apple-icon-57x57.png"><link rel="apple-touch-icon" sizes="60x60" href="/assets/img/favicons/apple-icon-60x60.png"><link rel="apple-touch-icon" sizes="72x72" href="/assets/img/favicons/apple-icon-72x72.png"><link rel="apple-touch-icon" sizes="76x76" href="/assets/img/favicons/apple-icon-76x76.png"><link rel="apple-touch-icon" sizes="114x114" href="/assets/img/favicons/apple-icon-114x114.png"><link rel="apple-touch-icon" sizes="120x120" href="/assets/img/favicons/apple-icon-120x120.png"><link rel="apple-touch-icon" sizes="144x144" href="/assets/img/favicons/apple-icon-144x144.png"><link rel="apple-touch-icon" sizes="152x152" href="/assets/img/favicons/apple-icon-152x152.png"><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-icon-180x180.png"><link rel="icon" type="image/png" sizes="192x192" href="/assets/img/favicons/android-icon-192x192.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="96x96" href="/assets/img/favicons/favicon-96x96.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/manifest.json"><meta name='msapplication-config' content='/assets/img/favicons/browserconfig.xml'><meta name="msapplication-TileColor" content="#ffffff"><meta name="msapplication-TileImage" content="/assets/img/favicons/ms-icon-144x144.png"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://fonts.gstatic.com"><link rel="preconnect" href="https://www.google-analytics.com" crossorigin="use-credentials"><link rel="dns-prefetch" href="https://www.google-analytics.com"><link rel="preconnect" href="https://www.googletagmanager.com" crossorigin="anonymous"><link rel="dns-prefetch" href="https://www.googletagmanager.com"><link rel="preconnect" href="cdn.jsdelivr.net"><link rel="dns-prefetch" href="cdn.jsdelivr.net"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.0.0/dist/css/bootstrap.min.css" integrity="sha256-LA89z+k9fjgMKQ/kq4OO2Mrf8VltYml/VES+Rg0fh20=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.11.2/css/all.min.css" integrity="sha256-+N4/V/SbAFiW1MPBCXnfnP9QSN3+Keu+NlB+0ev/YKQ=" crossorigin="anonymous"><link rel="stylesheet" href="/assets/css/style.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.css"> <script src="https://cdn.jsdelivr.net/npm/jquery@3/dist/jquery.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/popper.js@1.15.0,npm/bootstrap@4/dist/js/bootstrap.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.js"></script> <script defer src="https://www.googletagmanager.com/gtag/js?id=UA-89625019-1"></script> <script> document.addEventListener("DOMContentLoaded", function(event) { window.dataLayer = window.dataLayer || []; function gtag(){dataLayer.push(arguments);} gtag('js', new Date()); gtag('config', 'UA-89625019-1'); }); </script><body data-spy="scroll" data-target="#toc"><div id="sidebar" class="d-flex flex-column align-items-end"><div class="profile-wrapper text-center"><div id="avatar"> <a href="/" alt="avatar" class="mx-auto"> <img src="/assets/img/SANDOR_DARGO_ROUND.JPG" alt="avatar" onerror="this.style.display='none'"> </a></div><div class="site-title mt-3"> <a href="/">Sandor Dargo's Blog</a></div><div class="site-subtitle font-italic">On C++, software development and books</div></div><ul class="w-100"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home ml-xl-3 mr-xl-3 unloaded"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags ml-xl-3 mr-xl-3 unloaded"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive ml-xl-3 mr-xl-3 unloaded"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/books/" class="nav-link"> <i class="fa-fw fas fa-book ml-xl-3 mr-xl-3 unloaded"></i> <span>BOOKS</span> </a><li class="nav-item"> <a href="/speaking/" class="nav-link"> <i class="fa-fw fas fa-microphone ml-xl-3 mr-xl-3 unloaded"></i> <span>SPEAKING</span> </a><li class="nav-item"> <a href="/dailycpp/" class="nav-link"> <i class="fa-fw fas fa-link ml-xl-3 mr-xl-3 unloaded"></i> <span>DAILY C++</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info ml-xl-3 mr-xl-3 unloaded"></i> <span>HI...</span> </a></ul><ul class="w-100"><li class="nav-item"> <a href="https://www.patreon.com/sandordargo" class="nav-link"> <img src="https://c5.patreon.com/external/logo/become_a_patron_button.png"></a></ul><div class="sidebar-bottom mt-auto d-flex flex-wrap justify-content-center"> <a href="https://github.com/sandordargo" aria-label="github" class="order-3" target="_blank" rel="noopener"> <i class="fab fa-github-alt"></i> </a> <a href="https://twitter.com/SandorDargo" aria-label="twitter" class="order-4" target="_blank" rel="noopener"> <i class="fab fa-twitter"></i> </a> <a href=" javascript:location.href = 'mailto:' + ['sandor.dargo','gmail.com'].join('@')" aria-label="email" class="order-5" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" class="order-6" > <i class="fas fa-rss"></i> </a> <span class="icon-border order-2"></span> <span id="mode-toggle-wrapper" class="order-1"> <i class="mode-toggle fas fa-adjust"></i> <script type="text/javascript"> class ModeToggle { static get MODE_KEY() { return "mode"; } static get DARK_MODE() { return "dark"; } static get LIGHT_MODE() { return "light"; } constructor() { if (this.hasMode) { if (this.isDarkMode) { if (!this.isSysDarkPrefer) { this.setDark(); } } else { if (this.isSysDarkPrefer) { this.setLight(); } } } var self = this; /* always follow the system prefers */ this.sysDarkPrefers.addListener(function() { if (self.hasMode) { if (self.isDarkMode) { if (!self.isSysDarkPrefer) { self.setDark(); } } else { if (self.isSysDarkPrefer) { self.setLight(); } } self.clearMode(); } self.updateMermaid(); }); } /* constructor() */ setDark() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.DARK_MODE); } setLight() { $('html').attr(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); sessionStorage.setItem(ModeToggle.MODE_KEY, ModeToggle.LIGHT_MODE); } clearMode() { $('html').removeAttr(ModeToggle.MODE_KEY); sessionStorage.removeItem(ModeToggle.MODE_KEY); } get sysDarkPrefers() { return window.matchMedia("(prefers-color-scheme: dark)"); } get isSysDarkPrefer() { return this.sysDarkPrefers.matches; } get isDarkMode() { return this.mode == ModeToggle.DARK_MODE; } get isLightMode() { return this.mode == ModeToggle.LIGHT_MODE; } get hasMode() { return this.mode != null; } get mode() { return sessionStorage.getItem(ModeToggle.MODE_KEY); } /* get the current mode on screen */ get modeStatus() { if (this.isDarkMode || (!this.hasMode && this.isSysDarkPrefer) ) { return ModeToggle.DARK_MODE; } else { return ModeToggle.LIGHT_MODE; } } updateMermaid() { if (typeof mermaid !== "undefined") { let expectedTheme = (this.modeStatus === ModeToggle.DARK_MODE? "dark" : "default"); let config = { theme: expectedTheme }; /* re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */ $(".mermaid").each(function() { let svgCode = $(this).prev().children().html(); $(this).removeAttr("data-processed"); $(this).html(svgCode); }); mermaid.initialize(config); mermaid.init(undefined, ".mermaid"); } } flipMode() { if (this.hasMode) { if (this.isSysDarkPrefer) { if (this.isLightMode) { this.clearMode(); } else { this.setLight(); } } else { if (this.isDarkMode) { this.clearMode(); } else { this.setDark(); } } } else { if (this.isSysDarkPrefer) { this.setLight(); } else { this.setDark(); } } this.updateMermaid(); } /* flipMode() */ } /* ModeToggle */ let toggle = new ModeToggle(); $(".mode-toggle").click(function() { toggle.flipMode(); }); </script> </span></div></div><div id="topbar-wrapper" class="row justify-content-center topbar-down"><div id="topbar" class="col-11 d-flex h-100 align-items-center justify-content-between"> <span id="breadcrumb"> <span> <a href="/blog"> Blog </a> </span> <span> <a href="/2023"> 2023 </a> </span> <span> <a href="/07"> 07 </a> </span> <span> <a href="/19"> 19 </a> </span> <span>Binary sizes and compiler flags</span> </span> <i id="sidebar-trigger" class="fas fa-bars fa-fw"></i><div id="topbar-title"> Post</div><i id="search-trigger" class="fas fa-search fa-fw"></i> <span id="search-wrapper" class="align-items-center"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" placeholder="Search..."> <i class="fa fa-times-circle fa-fw" id="search-cleaner"></i> </span> <span id="search-cancel" >Cancel</span></div></div><div id="main-wrapper"><div id="main"><div class="row"><div id="post-wrapper" class="col-12 col-lg-11 col-xl-8"><div class="post pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><h1 data-toc-skip>Binary sizes and compiler flags</h1><div class="post-meta text-muted d-flex flex-column"><div> <span class="semi-bold"> Sandor Dargo </span> <span class="timeago " data-toggle="tooltip" data-placement="bottom" title="Wed, Jul 19, 2023, 12:00 AM +0200" prep="on" > Jul 19, 2023 <i class="unloaded">2023-07-19T00:00:00+02:00</i> </span></div><div> <span class="readtime" data-toggle="tooltip" data-placement="bottom" title="1475 words">8 min</span></div></div><div class="post-content"><p>During the last few months, we discussed a lot about how to write code to limit the size of our binary. <a href="https://www.sandordargo.com/blog/2023/02/08/binary-sizes-and-virtual">We should think twice if we want to turn a class into polymorphic</a>, <a href="https://www.sandordargo.com/blog/2023/03/29/binary-size-and-exceptions">exceptions also take a heavy toll</a> and we might end up <a href="https://www.sandordargo.com/blog/2023/02/01/special-functions-and-binary-sizes">defaulting special functions in the cpp file</a> which is quite unintuitive.</p><p>There are practices going against common sense and also that can be considered a best practice in any case. I think it’s good to know about them.</p><p>But how you compile your code is also important! Something I briefly mentioned in one of the first parts when it comes to optimization levels. But at that time we only talked about <code class="language-plaintext highlighter-rouge">-Os</code> and <code class="language-plaintext highlighter-rouge">-Oz</code>. Interestingly, they didn’t work well in my local experiments. <code class="language-plaintext highlighter-rouge">-O3</code> almost always produced better results and never worse. Maybe my scenarios were not big enough.</p><p>A few weeks ago, I presented my findings at <a href="https://www.meetup.com/mucplusplus/events/293377912/">MUC++</a>, and I was focusing on the programming techniques. During the after-talk discussion, I was told that if binary size is really a concern for me, then I should definitely try certain not-so-well-known compiler and linker settings and they kindly gave me a few suggestions. Many of them had been already applied by others, but now at least I understand what they mean!</p><p>Let me share those with you too, so that you also know and can experiment with them.</p><h2 id="optimize-for-space--os">Optimize for space: <code class="language-plaintext highlighter-rouge">-Os</code></h2><p>I already mentioned <code class="language-plaintext highlighter-rouge">-Os</code> at the beginning of the series, but I think it’s important to bring it up once again. One usually builds with <code class="language-plaintext highlighter-rouge">-O0</code> for debug builds to have the most information available for an eventual debugging session.</p><p>On the other hand, for release builds, one most often uses <code class="language-plaintext highlighter-rouge">-O3</code> to have an executable that is fast as possible - thanks to compiler optimizations. But if your goal is to have the smallest binary possible, you should consider <code class="language-plaintext highlighter-rouge">-Os</code> (or <code class="language-plaintext highlighter-rouge">-Oz</code> depending on the compiler). The compiler will <em>o</em>ptimize for <em>s</em>pace. It doesn’t give up performance though. It’ll do most of the optimizations that are done on <code class="language-plaintext highlighter-rouge">-O2</code> except for a few that would enlarge your binary, such as loop unrolling (we’ll see that later).</p><h2 id="link-time-optimization">Link Time Optimization</h2><p>What does the name Link Time Optimization (<em>LTO</em> in short) tell us? Not much to be honest. Some optimization would happen during link time, right?! Fair enough. It has another name which is a bit more revealing: Inter Procedural Optimization! So when LTO/IPO is enabled, the linker looks beyond individual object files and performs optimizations such as removing functions and even related global code and data that are never used. <a href="https://llvm.org/docs/LinkTimeOptimization.html#example-of-link-time-optimization">Here you can find a nice example</a>.</p><p>When LTO is enabled, source files are not directly translated to ELF/Mach-O or other object files, but they are translated into an intermediary bitcode. Out of those files, the linker can extract all the dependency information that it needs to finally optimize away some of the code and then it can create the optimized ELF/Mach-O/etc files that are optimized by the linker.</p><p>The fundamental way to trigger it is to pass <code class="language-plaintext highlighter-rouge">-flto</code>, but it has further options which are worth looking into when you decide to use it. These go beyond the scope of this article, but we might look into it in a future post.</p><h2 id="-fdata-sections---ffunction-sections-and--wl--gc-sections"><code class="language-plaintext highlighter-rouge">-fdata-sections</code> / <code class="language-plaintext highlighter-rouge">-ffunction-sections</code> and <code class="language-plaintext highlighter-rouge">-Wl,--gc-sections</code></h2><p>First of all, let me explain why I mention 3 options right away in one section. <code class="language-plaintext highlighter-rouge">-fdata-sections</code> and <code class="language-plaintext highlighter-rouge">-ffunction-sections</code> are similar in their nature and they won’t help you unless you pass <code class="language-plaintext highlighter-rouge">-Wl,--gc-sections</code> as well.</p><p><code class="language-plaintext highlighter-rouge">-fdata-sections</code> and <code class="language-plaintext highlighter-rouge">-ffunction-sections</code> place each piece of global data item and function respectively into its own section in the object file. If you only use these, your final binary will be larger. But if you pass <code class="language-plaintext highlighter-rouge">-Wl,--gc-sections</code>, the unused sections will not be part of your compiled and linked file and you can end up with a smaller binary.</p><p>Now let’s have a couple of remarks.</p><p><code class="language-plaintext highlighter-rouge">-Wl,--gc-sections</code> seems odd as a parameter when you first see it. Passing <code class="language-plaintext highlighter-rouge">-Wl</code> to gcc or clang means that what you’re passing after is meant to be an option for the linker, and not for the compiler. If you invoke the linker separately, you will have to pass <code class="language-plaintext highlighter-rouge">--gc-sections</code> on its own.</p><p>My second remark is about unused sections. If you read about these options, <a href="https://stackoverflow.com/questions/4274804/query-on-ffunction-section-fdata-sections-options-of-gcc">people often mention “unused code”</a>. That’s misleading. You might think that this is a tool then to identify code that is written but nowhere used. That’s not the case.</p><p>When the linker has to resolve a certain symbol - let’s say <code class="language-plaintext highlighter-rouge">foo()</code> - in another object file, then once it finds it, it’ll include the entire <code class="language-plaintext highlighter-rouge">.text</code> section. Potentially with lots of code that you don’t use. Unused code in that sense. If each function and piece of global data have its own section, the linker will only include the needed sections thus you might gain a considerable amount of space.</p><p>And here is the third remark. Don’t forget to measure. Depending on your code, you might not gain a lot of space and if that’s your case, then don’t use these because they make compilations and linking slower and if there are some “magic” sections that are needed for your program but they are nowhere referenced in the functions that you use, your program will misbehave. You can find more info on this <a href="https://elinux.org/images/2/2d/ELC2010-gc-sections_Denys_Vlasenko.pdf">here starting from slide 9</a>.</p><p>All-in-all, these options are really useful, just don’t forget to measure and test first!</p><h2 id="-wl--icfall-or--wl--icfsafe"><code class="language-plaintext highlighter-rouge">-Wl,--icf=all</code> or <code class="language-plaintext highlighter-rouge">-Wl,--icf==safe</code></h2><p>We often have functions whose bodies are almost identical. You might say that’s not good and one should follow the DRY principle and don’t repeat the same code over and over again, but it’s not always the case, you might not want to reuse the same code in completely different contexts. In any case, you might end up with identical code.</p><p>Of course, when you want to bring down binary size, it feels like a big waste to store the generated code for identical functions.</p><p>Luckily, compiler and linker implementers already thought about that! What you might look for is _<strong>i</strong>dentical <strong>c</strong>ode <strong>f</strong>olding__, in short <em>icf</em>.</p><p>According to some Google experiments, this technique might reduce the size of your binary by 6%!</p><p>You can turn it on by passing <code class="language-plaintext highlighter-rouge">--icf=all</code> to your linker, or <code class="language-plaintext highlighter-rouge">-Wl,--icf=all</code> if you go through your compiler. We must note that ICF might cause some issues if you use functions as keys in a map for example. Then the same piece of code - which would normally be two different pieces of code - would practically be used as a map key twice which is obviously a problem. To avoid such issues, you can use <code class="language-plaintext highlighter-rouge">--icf=safe</code>. It will decrease a bit the gain, but the benefits will be still significant.</p><blockquote><p>When you want to benefit from ICF, you should also consider setting <code class="language-plaintext highlighter-rouge">-faddrsig</code>. This switch controls whether Clang (have you found something similar in GCC?) emits an address-significance table into object files. These tables allow the linkers to implement ICF without too many false positives.</p></blockquote><h2 id="-mllvm--inline-thresholdn"><code class="language-plaintext highlighter-rouge">-mllvm -inline-threshold=&lt;n&gt;</code></h2><p>Clang lets you drive - or at least give a hint - how much it should inline functions through the <code class="language-plaintext highlighter-rouge">-mllvm -inline-threshold=&lt;n&gt;</code> setting where <em>n</em> is set to 255 by default. The corresponding compiler setting for gcc is <code class="language-plaintext highlighter-rouge">-finline-limit</code>.</p><p>The smaller <em>n</em> is, the less inlining will happen, thus the smaller your binary will be. On the other hand, by increasing the value of <em>n</em>, you will end up with more inlining, a bigger binary and potentially faster code.</p><p>Don’t just play with this setting blindly, measure the effects to avoid bad surprises, both in terms of binary size and also regarding run-time performance.</p><h2 id="-fno-unroll-loops"><code class="language-plaintext highlighter-rouge">-fno-unroll-loops</code></h2><p>A well-known optimization technique used by all compilers is to replace loops with their body repeated the necessary number of times.</p><div class="language-cpp highlighter-rouge"><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="c1">// the original loop</span>

<span class="k">for</span> <span class="p">(</span><span class="kt">size_t</span> <span class="n">i</span> <span class="o">=</span> <span class="mi">0</span><span class="p">;</span> <span class="n">i</span> <span class="o">&lt;</span> <span class="mi">5</span><span class="p">;</span> <span class="o">++</span><span class="n">i</span><span class="p">)</span> <span class="p">{</span>
	<span class="n">foo</span><span class="p">();</span>
<span class="p">}</span>

<span class="c1">// the unrolled version</span>
<span class="n">foo</span><span class="p">();</span>
<span class="n">foo</span><span class="p">();</span>
<span class="n">foo</span><span class="p">();</span>
<span class="n">foo</span><span class="p">();</span>
<span class="n">foo</span><span class="p">();</span>
</pre></table></code></div></div><p>If someone would write the latter code, you’d never let it merge. Still, the compiler might do this optimization. It’s bad for the binary size, but it might be better for the run-time there is no need to jump around and maintain a loop variable.</p><p>If you’re desperate to gain a few bytes, you might try this!</p><h2 id="conclusion">Conclusion</h2><p>In this article, we reviewed compiler and linker options that help us reduce the size of the binary. Just don’t forget to measure the effects, because these are usually compromises between the space your executable needs and the time it requires to execute. Which ones you can take are always based on your constraints.</p><h2 id="connect-deeper">Connect deeper</h2><p>If you liked this article, please</p><ul><li>hit on the like button,<li><a href="http://eepurl.com/gvcv1j">subscribe to my newsletter</a><li>and let’s connect on <a href="https://twitter.com/SandorDargo">Twitter</a>!</ul><a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw mr-1"></i> <a href='/categories/dev/'>dev</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw mr-1"></i> <a href="/tags/cpp/" class="post-tag no-text-decoration" >cpp</a> <a href="/tags/binarysizes/" class="post-tag no-text-decoration" >binarysizes</a> <a href="/tags/compiler/" class="post-tag no-text-decoration" >compiler</a> <a href="/tags/linker/" class="post-tag no-text-decoration" >linker</a></div><div class="post-tail-bottom d-flex justify-content-between align-items-center mt-3 pt-5 pb-2"><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a> by the author.</div><a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a><div class="share-wrapper"> <a href="https://www.patreon.com/sandordargo" style="float: left; padding-left: 0;"><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://c5.patreon.com/external/logo/become_a_patron_button.png" style="float: left; padding-left: 0;"></a> <span class="share-label text-muted mr-1">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Binary sizes and compiler flags - Sandor Dargo's Blog&url=https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" data-toggle="tooltip" data-placement="top" title="Twitter" target="_blank" rel="noopener" aria-label="Twitter"> <i class="fa-fw fab fa-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Binary sizes and compiler flags - Sandor Dargo's Blog&u=https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" data-toggle="tooltip" data-placement="top" title="Facebook" target="_blank" rel="noopener" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://telegram.me/share?text=Binary sizes and compiler flags - Sandor Dargo's Blog&url=https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" data-toggle="tooltip" data-placement="top" title="Telegram" target="_blank" rel="noopener" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <a href="https://news.ycombinator.com/submitlink?t=Binary sizes and compiler flags - Sandor Dargo's Blog&u=https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags" data-toggle="tooltip" data-placement="top" title="HackerNews" target="_blank" rel="noopener" aria-label="HackerNews"> <i class="fa-fw fab fa-hacker-news"></i> </a> <i class="fa-fw fas fa-link small" onclick="copyLink()" data-toggle="tooltip" data-placement="top" title="Copy link"></i> </span></div></div></div></div></div><div id="panel-wrapper" class="col-xl-3 pl-2 text-muted topbar-down"><div class="access"><div id="access-lastmod" class="post"> <span>Recent Update</span><ul class="post-content pl-0 pb-1 ml-1 mt-2"><li><a href="/blog/2025/10/22/trip-report-budapest-cpp">Trip report: Budapest C++ - Breaking & Building C++</a><li><a href="/blog/2025/10/01/cpp26-optional-of-reference">C++26: std::optional&lt;T&amp;&gt;</a><li><a href="/blog/2025/09/24/trip-report-cppcon-2025">Trip report: CppCon 2025</a><li><a href="/blog/2025/07/23/format-your-own-type-part-1">Format your own type (Part 1)</a><li><a href="/blog/2025/07/02/cpponsea-trip-report">Trip report: C++ On Sea 2025</a></ul></div><div id="access-tags"> <span>Trending Tags</span><div class="d-flex flex-wrap mt-3 mb-1 mr-3"> <a class="post-tag" href="/tags/cpp/">cpp</a> <a class="post-tag" href="/tags/books/">books</a> <a class="post-tag" href="/tags/watercooler/">watercooler</a> <a class="post-tag" href="/tags/career/">career</a> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/cpp23/">cpp23</a> <a class="post-tag" href="/tags/stl/">stl</a> <a class="post-tag" href="/tags/algorithms/">algorithms</a> <a class="post-tag" href="/tags/self-improvement/">self-improvement</a> <a class="post-tag" href="/tags/management/">management</a></div></div></div><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@1.0.1/dist/bootstrap-toc.min.js"></script><div id="toc-wrapper" class="pl-0 pr-4 mb-5"> <span class="pl-3 pt-2 mb-2">Contents</span><nav id="toc" data-toggle="toc"></nav></div></div></div><div class="row"><div class="col-12 col-lg-11 col-xl-8"><div id="post-extend-wrapper" class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-md-4 pr-md-4"><div id="related-posts" class="mt-5 mb-2 mb-sm-4"><h3 class="pt-2 mt-1 mb-4 ml-1" data-toc-skip>Further Reading</h3><div class="card-deck mb-4"><div class="card"> <a href="/blog/2024/06/26/member-ordering-and-binary-size"><div class="card-body"> <span class="timeago small" > Jun 26, 2024 <i class="unloaded">2024-06-26T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Member ordering and binary sizes</h3><div class="text-muted small"><p> While I have been preparing my presentation for C++ On Sea, I realized that something is missing from How to keep your binaries small. The importance of member ordering! I remember learning at a p...</p></div></div></a></div><div class="card"> <a href="/blog/2024/07/31/rule-of-5-once-again"><div class="card-body"> <span class="timeago small" > Jul 31, 2024 <i class="unloaded">2024-07-31T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>Once more about the rule of 5</h3><div class="text-muted small"><p> Arne Mertz talked about misused guidelines at C++OnSea. Among those, there was the rule of 5. Which made me think about a pattern I’ve seen. Let’s first repeat what the rule of 5 says. The Rule...</p></div></div></a></div><div class="card"> <a href="/blog/2024/08/07/rule-of-five-and-base-classes"><div class="card-body"> <span class="timeago small" > Aug 7, 2024 <i class="unloaded">2024-08-07T00:00:00+02:00</i> </span><h3 class="pt-0 mt-1 mb-3" data-toc-skip>The rule of 5 and inheritance</h3><div class="text-muted small"><p> Last week, we talked about the rule of five and we discovered what it means for move operations if we only declare a destructor and not the rest of the special member functions. In that case, move ...</p></div></div></a></div></div></div><div class="post-navigation d-flex justify-content-between"> <a href="/blog/2023/07/12/cpp23-extended-init-statement-with-alias-declaration" class="btn btn-outline-primary" prompt="Older"><p>C++23: Alias declarations in for loop init-statements</p></a> <a href="/blog/2023/07/26/cpp23-static-call-and-subscript-operator" class="btn btn-outline-primary" prompt="Newer"><p>C++23: static operator() and static operator[]</p></a></div><div id="disqus" class="pt-2 pb-2"><p class="text-center text-muted small pb-5"> Comments powered by <a href="https://disqus.com/">Disqus</a>.</p></div><script src="/assets/js/lib/jquery.disqusloader.min.js"></script> <script> const options = { scriptUrl: '//sandordargo-github-io.disqus.com/embed.js', disqusConfig: function() { this.page.title = 'Binary sizes and compiler flags'; this.page.url = 'https://www.sandordargo.com/blog/2023/07/19/binary-sizes-and-compiler-flags'; this.page.identifier = '/blog/2023/07/19/binary-sizes-and-compiler-flags'; } }; $.disqusLoader('#disqus', options); </script></div></div></div><script type="text/javascript" src="https://cdn.jsdelivr.net/npm/lozad/dist/lozad.min.js"></script> <script type="text/javascript"> const imgs = document.querySelectorAll('.post-content img'); const observer = lozad(imgs); observer.observe(); </script><div id="amzn-assoc-ad-be5a767b-3346-40aa-bc00-2eff0ce33d2b"></div><script async src="//z-na.amazon-adsystem.com/widgets/onejs?MarketPlace=US&adInstanceId=be5a767b-3346-40aa-bc00-2eff0ce33d2b"></script> <script type="text/javascript" src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.4/js/bootstrap.min.js"></script> <script type="text/javascript" src="//downloads.mailchimp.com/js/signup-forms/popup/embed.js" data-dojo-config="usePlainJson: true, isDebug: false"></script><script type="text/javascript">require(["mojo/signup-forms/Loader"], function(L) { L.start({"baseUrl":"mc.us16.list-manage.com","uuid":"b073dbd5c29322302f59a8cd8","lid":"d26240427e"}) })</script><footer class="d-flex w-100 justify-content-center"><div class="d-flex justify-content-between align-items-center"><div class="footer-left"><p class="mb-0"> © 2025 <a href="https://twitter.com/SandorDargo">Sandor Dargo</a>. <span data-toggle="tooltip" data-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author.">Some rights reserved.</span></p></div><div class="footer-right"><p class="mb-0"> Powered by <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a> with <a href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener">Chirpy</a> theme.</p></div></div></footer></div><div id="search-result-wrapper" class="d-flex justify-content-center unloaded"><div class="col-12 col-sm-11 post-content"><div id="search-hints"><h4 class="text-muted mb-4">Trending Tags</h4><a class="post-tag" href="/tags/cpp/">cpp</a> <a class="post-tag" href="/tags/books/">books</a> <a class="post-tag" href="/tags/watercooler/">watercooler</a> <a class="post-tag" href="/tags/career/">career</a> <a class="post-tag" href="/tags/tutorial/">tutorial</a> <a class="post-tag" href="/tags/cpp23/">cpp23</a> <a class="post-tag" href="/tags/stl/">stl</a> <a class="post-tag" href="/tags/algorithms/">algorithms</a> <a class="post-tag" href="/tags/self-improvement/">self improvement</a> <a class="post-tag" href="/tags/management/">management</a></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><div id="mask"></div><a id="back-to-top" href="#" aria-label="back-to-top" class="btn btn-lg btn-box-shadow" role="button"> <i class="fas fa-angle-up"></i> </a> <script src="https://cdn.jsdelivr.net/npm/simple-jekyll-search@1.7.3/dest/simple-jekyll-search.min.js"></script> <script> SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<div class="pl-1 pr-1 pl-sm-2 pr-sm-2 pl-lg-4 pr-lg-4 pl-xl-0 pr-xl-0"> <a href="https://www.sandordargo.com{url}">{title}</a><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div><p>{snippet}</p></div>', noResultsText: '<p class="mt-5">Oops! No result founds.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="mr-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); </script>
